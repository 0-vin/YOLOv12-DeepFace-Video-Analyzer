import cv2
import os
import uuid
from ultralytics import YOLO
from deepface import DeepFace
from yt_dlp import YoutubeDL
import time
from typing import List, Tuple, Optional
import argparse
from scipy.spatial import distance


# ---------------- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ë™ì¼) ----------------
def get_unique_name(base_name: str, extension: str) -> str:
    unique_id = uuid.uuid4().hex[:8]
    return f"{base_name}_{unique_id}.{extension}"


def merge_intervals(timestamps: List[float], gap: float = 2.0) -> List[Tuple[float, float]]:
    if not timestamps: return []
    timestamps.sort()
    intervals = []
    try:
        start = timestamps[0]
        prev = timestamps[0]
    except IndexError:
        return []
    for t in timestamps[1:]:
        if t - prev <= gap:
            prev = t
        else:
            intervals.append((start, prev))
            start = t
            prev = t
    intervals.append((start, prev))
    return intervals


def format_time(seconds: float) -> str:
    mins = int(seconds // 60)
    secs = seconds % 60
    return f"{mins:02d}:{secs:05.2f}"


def download_video(url: str, output_dir: str = "downloads") -> Optional[str]:
    # (ê¸°ì¡´ ë‹¤ìš´ë¡œë“œ ë¡œì§ê³¼ ë™ì¼í•˜ì—¬ ë‚´ìš© ìƒëµ ì—†ì´ ìœ ì§€)
    os.makedirs(output_dir, exist_ok=True)
    unique_id = uuid.uuid4().hex[:8]
    output_template = os.path.join(output_dir, f"%(title)s_{unique_id}.%(ext)s")
    ydl_opts = {
        "format": "bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo+bestaudio/best",
        "outtmpl": output_template,
        "merge_output_format": "mp4",
        "quiet": True,  # ë¡œê·¸ ë„ˆë¬´ ê¸¸ì–´ì„œ ì¡°ê¸ˆ ì¤„ì„
        "postprocessors": [{'key': 'FFmpegVideoConvertor', 'preferedformat': 'mp4'}],
    }
    print(f" ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {url}")
    try:
        with YoutubeDL(ydl_opts) as ydl:
            info_dict = ydl.extract_info(url, download=True)
            if info_dict:
                final_filepath = info_dict.get('filepath') or info_dict.get('_filename')
                # yt-dlpê°€ ê°€ë” ê²½ë¡œë¥¼ ë°”ë¡œ ì•ˆ ì¤„ ë•Œê°€ ìˆì–´ì„œ ì•ˆì „ì¥ì¹˜
                if not final_filepath:
                    filename = ydl.prepare_filename(info_dict)
                    final_filepath = filename.replace('.webm', '.mp4').replace('.mkv', '.mp4')

                if final_filepath and os.path.exists(final_filepath):
                    print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {final_filepath}")
                    return final_filepath
            return None
    except Exception as e:
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None


# ---------------- ì˜ìƒ ë¶„ì„ í´ë˜ìŠ¤ ----------------
class VideoFaceAnalyzer:
    def __init__(self, yolo_model_path: str, deepface_model_name: str, device: str = 'cpu'):
        self.deepface_model_name = deepface_model_name  # ëª¨ë¸ ì´ë¦„ ì €ì¥

        # 1. YOLO ëª¨ë¸ ë¡œë“œ
        print(f"ğŸš€ YOLO ëª¨ë¸ ë¡œë“œ ì¤‘... ({yolo_model_path})")
        try:
            self.model = YOLO(yolo_model_path)
            self.model.to(device)
        except Exception as e:
            print(f"âŒ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

        # 2. DeepFace ëª¨ë¸ ë¹Œë“œ (ì²« ì‹¤í–‰ ë”œë ˆì´ ë°©ì§€)
        print(f"ğŸ§  DeepFace ëª¨ë¸ ì¤€ë¹„ ì¤‘... ({self.deepface_model_name})")
        try:
            DeepFace.build_model(self.deepface_model_name)
        except Exception as e:
            print(f"âš ï¸ DeepFace ëª¨ë¸ ë¹Œë“œ ì¤‘ ê²½ê³  (ë¬´ì‹œ ê°€ëŠ¥): {e}")

    def analyze_video(self, video_path: str, reference_face_path: str, checks_per_sec: float) -> List[float]:
        # 1. ì°¸ì¡° ì–¼êµ´ ì„ë² ë”© ë¯¸ë¦¬ ê³„ì‚°
        print(f"ğŸ“¸ ì°¸ì¡° ì–¼êµ´ ë¶„ì„ ì¤‘: {reference_face_path}")
        if not os.path.exists(reference_face_path):
            print("âŒ ì°¸ì¡° ì–¼êµ´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []

        try:
            # SFace ì‚¬ìš© ì‹œ ì„ê³„ê°’ì„ ì¡°ê¸ˆ ë‚®ì¶”ëŠ” ê²ƒì´ ì¢‹ìŒ (ArcFace: 0.68, SFace: 0.4~0.5 ê¶Œì¥)
            if self.deepface_model_name == "SFace":
                threshold = 0.5
            else:
                threshold = 0.68

                # ì°¸ì¡° ì´ë¯¸ì§€ ì„ë² ë”© ì¶”ì¶œ
            ref_results = DeepFace.represent(
                img_path=reference_face_path,
                model_name=self.deepface_model_name,  # â˜… ì„¤ì •í•œ ëª¨ë¸ ì‚¬ìš©
                enforce_detection=False
            )
            ref_embedding = ref_results[0]["embedding"]
            print(f" ì°¸ì¡° ì–¼êµ´ ì„ë² ë”© ì™„ë£Œ (Threshold: {threshold})")

        except Exception as e:
            print(f" ì°¸ì¡° ì–¼êµ´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return []

        # 2. ë¹„ë””ì˜¤ ì„¤ì •
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        if fps == 0: fps = 30.0

        # ê²€ì‚¬ ê°„ê²© ê³„ì‚°
        if checks_per_sec <= 0: checks_per_sec = 2.0
        skip_interval = int(fps / checks_per_sec)
        if skip_interval < 1: skip_interval = 1

        frame_idx = 0
        timestamps = []
        last_log_time = time.time()

        print(f"ï¸ ë¶„ì„ ì‹œì‘ (FPS: {fps:.2f} | {skip_interval}í”„ë ˆì„ë§ˆë‹¤ ê²€ì‚¬)")

        while True:
            ret, frame = cap.read()
            if not ret: break

            if frame_idx % skip_interval == 0:
                current_time = frame_idx / fps

                # ì§„í–‰ìƒí™© ë¡œê·¸
                if time.time() - last_log_time > 3.0:
                    print(f"   ... {format_time(current_time)} ì§„í–‰ ì¤‘")
                    last_log_time = time.time()

                # YOLO ê°ì§€
                results = self.model(frame, verbose=False, conf=0.5)  # confidence 0.5 ì´ìƒë§Œ

                for box in results[0].boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])

                    # ì´ë¯¸ì§€ ìë¥´ê¸° (ê²½ê³„ì„  ì²˜ë¦¬ í¬í•¨)
                    h, w = frame.shape[:2]
                    face_crop = frame[max(0, y1):min(h, y2), max(0, x1):min(w, x2)]

                    # ë„ˆë¬´ ì‘ì€ ì–¼êµ´ ë¬´ì‹œ (ì†ë„ í–¥ìƒ)
                    if face_crop.shape[0] < 40 or face_crop.shape[1] < 40:
                        continue

                    try:
                        # DeepFace ì…ë ¥ ì „ BGR -> RGB
                        face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)

                        # íƒ€ê²Ÿ ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ
                        target_res = DeepFace.represent(
                            img_path=face_rgb,
                            model_name=self.deepface_model_name,  # â˜… ì„¤ì •í•œ ëª¨ë¸ ì‚¬ìš©
                            enforce_detection=False
                        )
                        target_embedding = target_res[0]["embedding"]

                        # ì½”ì‚¬ì¸ ê±°ë¦¬ ê³„ì‚°
                        dist = distance.cosine(ref_embedding, target_embedding)

                        if dist <= threshold:
                            print(f" ì°¾ìŒ! {format_time(current_time)} (ê±°ë¦¬: {dist:.4f})")
                            timestamps.append(current_time)
                            break  # í•œ í”„ë ˆì„ì—ì„œ ì°¾ìœ¼ë©´ ì¤‘ë³µ ê²€ì‚¬ ë°©ì§€

                    except Exception:
                        continue

            frame_idx += 1

        cap.release()
        return timestamps


# ---------------- ë©”ì¸ ì‹¤í–‰ë¶€ ----------------
def main():
    parser = argparse.ArgumentParser(description="ì˜ìƒ ì¸ë¬¼ íƒì§€ê¸°")

    # [í•„ìˆ˜ ì˜µì…˜] ì‚¬ìš©ìê°€ ê¼­ ì…ë ¥í•´ì•¼ í•˜ëŠ” ê²ƒë“¤
    parser.add_argument("--url", type=str, required=True, help="ìœ íŠœë¸Œ ì˜ìƒ ì£¼ì†Œ")
    parser.add_argument("--face", type=str, required=True, help="ì°¾ì„ ì‚¬ëŒ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--cps", type=float, required=True, help="ì´ˆë‹¹ ê²€ì‚¬ íšŸìˆ˜ (ì˜ˆ: 2)")

    # [ì„ íƒ ì˜µì…˜] ì…ë ¥ ì•ˆ í•˜ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    parser.add_argument("--yolo", type=str, default="/home/0vin/yolodeep/model_pt/yolov12n-face.pt",
                        help="YOLO ëª¨ë¸ ê²½ë¡œ (.pt)")
    parser.add_argument("--deepface", type=str, default="ArcFace", help="DeepFace ëª¨ë¸ ì´ë¦„ (ArcFace, SFace ë“±)")
    parser.add_argument("--device", type=str, default="cpu", help="ì—°ì‚° ì¥ì¹˜ (cpu ë˜ëŠ” cuda)")

    args = parser.parse_args()

    # ì‹¤í–‰
    video_file = download_video(args.url)
    if not video_file: return

    analyzer = VideoFaceAnalyzer(
        yolo_model_path=args.yolo,
        deepface_model_name=args.deepface,
        device=args.device
    )

    start_t = time.time()
    timestamps = analyzer.analyze_video(video_file, args.face, checks_per_sec=args.cps)
    end_t = time.time()

    # ê²°ê³¼ ì €ì¥
    intervals = merge_intervals(timestamps)
    save_path = get_unique_name("result", "txt")

    with open(save_path, "w", encoding="utf-8") as f:
        f.write(f"Video: {args.url}\n")
        f.write(f"Target: {args.face}\n")
        f.write(f"Model: YOLO={args.yolo} | DeepFace={args.deepface}\n")
        f.write(f"Time: {end_t - start_t:.2f}s\n")
        f.write("-" * 20 + "\n")
        for s, e in intervals:
            f.write(f"{format_time(s)} ~ {format_time(e)}\n")

    print(f"\n ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")


if __name__ == "__main__":
    main()